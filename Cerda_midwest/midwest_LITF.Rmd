---
title: "Midwest survey using One-hot, CA, CA0, PCO, and Cerda similarity methods"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
library(tidyverse)
library(here)
```

```{r, echo=FALSE}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```
 
```{r, include=FALSE, message=FALSE}
# Load libraries
library(ranger)
library(caret)   # for createFolds
library(stringdist)   # for distance matrix

# Load in our functions (PCO not required as pre-transforming data)
source(here("methods","tree_predictions.R")) # to pull out individual tree predictions
source(here("methods","ranger_mods.R"))
source(here("methods","ca.R")) # CA method
source(here("methods","binary.R")) # Binary method
source(here("methods","ca_unbiased.R"))  # CA method with new levels scored as zero
source(here("methods","pco.R")) # PCO method
source(here("methods","similarity.R"))

```

#### `r colorize("1. Data preparation", "blue")`

**Load data**

Midwest survey data from Cerda et al 2018.  
Survey to know if people self-identify as Midwesterners.  
Sample size:  2,778.   
Target variable (multiclass-clf): ‘Location (Census Region)’ (9 classes) - Cerda says 10 so perhaps includes missing, although they remove these rows anyway.
Cerda selected categorical variable: ‘In your own words, what would you call the part of the country you live in now?’ (cardinality: 1,008) - again Cerda had extra one perhaps for missing. Also when converting all to lower case, the cardinality drops to 843  
Other explanatory variables: ‘Personally identification as a Midwesterner?’ (4 levels, ordinal), ‘Gender’ (2 levels), ‘Age’ (4 levels, ordinal), ‘Household Income’ (5 levels, ordinal), ‘Education’ (5 levels, ordinal), ‘Illinois (IL) in the Midwest?’, ‘IN?’, ‘IA?’, ‘KS?’, ‘MI?’, ‘MN?’, ‘MO?’, ‘NE?’, ‘ND?’, ‘OH?’, ‘SD?’, ‘WI?’, ‘AR?’, ‘CO?’, ‘KY?’, ‘OK?’, ‘PA?’, ’WV?’, ’MT?’, ‘WY?’ (each of these last variables are indicator variables, although an individual can belong to more than one).

```{r}
midwest_raw <- read.csv(here("Cerda_midwest","midwest_data","midwest_survey.csv"), header=T, na.strings=c(""," ","NA"))
```

```{r, include=FALSE}
str(midwest_raw)
midwest_raw |> map_df(function(x){x |> as.factor() |> nlevels()}) |> t()
midwest_raw |> pull(categorical_variable) |> as.factor() |> nlevels()  # 1008 levels
midwest_raw |> mutate(categorical_variable=tolower(categorical_variable)) |> pull(categorical_variable) |> as.factor() |> nlevels() # 843 levels after making all lower case
midwest_raw |> mutate(categorical_variable=tolower(categorical_variable)) |> filter(!is.na(census_region)) |> pull(categorical_variable) |> as.factor() |> nlevels() # 780 levels are removing rows with missing target
```



**Data preprocessing:**

-- remove rows with missing values for the target variable or in any explanatory variable other than the selected categorical variable (reduces to 2421 observations);  
-- for the selected categorical variable replace missing entries by the string ‘nan’;  
-- transform all entries for the categorical variable to lower case;  
-- convert all variables to ordinal, binary, or nominal factors.

Note that Cerda 2018 standardized every column of the feature matrix to a unit variance


```{r}
midwest_tidy <- midwest_raw |> 
  # remove id (because it contains rows that will be removed) and respondent
  select(-id, -respondent) |> 
  # fill in binary zeros
  mutate(across(IL:WY, \(.) {replace(.,is.na(.),0)})) |> 
  # remove rows with missing values for the target variable census_region
  filter(!is.na(census_region)) |> 
  # remove na from categorical_variable to avoid na in distance matrix
  # need to change to string (rather than "") so can use tidymodels with probability forests
  mutate(across(categorical_variable, \(.) {replace(.,is.na(.),"nan")})) |> 
  # remove rows with missing values for explanatory variables other than the selected categorical variable
  drop_na(where(is.character)) |> 
  # transform all entries for the categorical variable to lower case
  mutate(categorical_variable = tolower(categorical_variable)) |> 
  # re-add id
  rownames_to_column("id") |> 
  # convert ordinal variables to ordered factors
  mutate(education = factor(education, levels=c("Some college", "Less than high school degree", "High school degree", "Associate or bachelor degree", "Graduate degree"), ordered=TRUE, exclude = NULL), 
         age = factor(age, levels=c("18-29", "30-44", "45-60", "> 60"), ordered=TRUE, exclude = NULL), 
         household_income = factor(household_income, levels=c("$0 - $24,999", "$25,000 - $49,999", "$50,000 - $99,999", "$100,000 - $149,999", "$150,000+"), ordered=TRUE, exclude = NULL),
         personal_id = factor(personal_id, levels=c("Not at all","Not much","Some","A lot"), ordered=TRUE, exclude = NULL)) |> 
  # convert character variables to factors
  mutate(across(!where(is.numeric), factor)) |> 
  # convert all predictor variables other than the categorical_variable to numeric
  mutate(across(where(is.factor) & -c(id, census_region, categorical_variable), as.numeric))

```

Because of all the spaces and dots in the categorical variable levels, `make.names()` will reduce the number of unique levels, so we need to make them unique to start with.

```{r}
unique_levels <- data.frame(categorical_variable = levels(midwest_tidy$categorical_variable)) |> 
  mutate(unique_categorical_variable = categorical_variable |> make.names(unique = TRUE))

midwest <- midwest_tidy |> left_join(unique_levels, by="categorical_variable") |> mutate(categorical_variable = as.factor(unique_categorical_variable), .keep="unused") 

str(midwest)

```


**Define the data**

```{r, eval=FALSE, include=FALSE}
# Add a prefix ("Var") to all the predictor variables names (so the functions can recognise the predictors).
# Add a prefix ("Ignore") to the numerical variable names so the functions will ignore them.
# This isn't necessary as there's only one variable so will just name it directly 

midwest <- midwest |> 
  rename_with(.fn = function(.x){paste0("Var_", .x)}, .cols=categorical_variable) |> 
  rename_with(.fn = function(.x){paste0("Ignore_", .x)}, .cols=-c(id, Var_categorical_variable, census_region))

str(midwest)
```

The different methods will use different encodings of the categorical_variable column.  
The data is now exactly the same for each method


**Calculate distance matrix** - Levenshtein distance "lv" ("hamming" only works when strings are the same length)

The categorical variables are either binary or ordinal apart from 'categorical_variable'.
Calculate a distance matrix for this variable only. It needs to be in a list for the pco and similarity functions though.

```{r}
d <- list(categorical_variable = stringdistmatrix(midwest$categorical |> unique(), midwest$categorical |> unique(), 
                                                  method = "lv", useNames = "strings"))
```


**Make a list for the methods**

```{r}
list.of.data <- list(ca=midwest,
                     binary=midwest,
                     ca0=midwest,
                     pco=midwest,
                     similarity=midwest)

```

#### `r colorize("2. Prepare data according to method", "blue")`

**Split data into training and test sets using folds**

```{r}
set.seed(3)
flds <- createFolds(y=midwest$census_region, k=10) 

list.of.train <- map(list.of.data, function(x) {map(flds, ~slice(x, {-.}))})
list.of.test <- map(list.of.data, function(x) {map(flds, ~slice(x, .))})

```

Table of counts in each target region shows that the census regions are very imbalanced.

```{r}
list.of.test$ca |> bind_rows() |> pull(census_region) |> table()
```

**Transform the predictor variable(s) according to each method**

Note that the ca method doesn't allow for numeric columns or else we could just use the ca method on the transformed data.

```{r}
list.of.methods <- list(ca="ca", binary="binary",ca0="ca0", pco="pco", similarity="similarity")

list.of.prepped.data <- pmap(list(list.of.train, list.of.test, list.of.methods), 
                             function(x, y, z) {
                               map2(x, y, ~prep_data(.x, .y, method=z, 
                                                     class = "census_region", id="id", var_id="categorical", d=d, axes=2))})
```

What proportion of variation is captured by the pco axes?  
The first axis is capturing approximated 55% and the second axis approximately 4%.  
Roughly 30 axes are needed to capture 95% of the variation in d; and 36 axes to capture 99%.  

```{r}
propG <- list.of.prepped.data$pco$Fold01$train$extra$categorical_variable$propG
cumsum(propG/sum(propG)*100)

propG <- list.of.prepped.data$pco |> map(c("train", "extra", "categorical_variable", "propG"))
propG |> map(function(x) (x/sum(x)*100)[1:2])
propG |> map(function(x){cumsum(x/sum(x)*100)[1:2]})
propG |> map(function(x){y = cumsum(x/sum(x)*100)
                         y[which(y <= 95)] |> length()})
propG |> map(function(x){y = cumsum(x/sum(x)*100)
                         y[which(y <= 99)] |> length()})

```

Increase the number of axes to 36.

```{r}
list.of.prepped.data$pco <- map2(list.of.train$pco, list.of.test$pco, ~prep_data(.x, .y, method=list.of.methods$pco, 
                                                     class = "census_region", id="id", var_id="categorical", d=d, axes=36))
```


#### `r colorize("3. Train random forest models", "blue")`

First merge the prepped data with the ignored (numeric) columns, then train the ranger models

```{r, warning=FALSE}
numtrees <- 500

list.of.models <- pmap(
  list(list.of.prepped.data, list.of.train, list.of.test, list.of.methods), 
  function(prepped.folds, train.folds, test.folds, method){
    pmap(list(prepped.folds, train.folds, test.folds), 
         function(prepped.dat, train.dat, test.dat, ntrees=numtrees, class="census_region", id="id"){
           other.train <- train.dat |> select(-c(id, categorical_variable, census_region))
           other.test <- test.dat |> select(-c(categorical_variable, census_region))
           train_dat <- prepped.dat$train$training |> bind_cols(other.train) # hoping this lines up correctly
           test_dat <- prepped.dat$test |> left_join(other.test, by="id")
           classes <- train_dat |> pull(class) #|> droplevels()
           ranger_mod <- if(method=="binary") {
             ranger(dependent.variable.name = class, data = train_dat, 
                    oob.error = TRUE, num.trees=ntrees, respect.unordered.factors = TRUE)
           } else {
             ranger(classes ~ ., data=train_dat |> select(-any_of(class)), 
                    oob.error = TRUE, num.trees=ntrees, respect.unordered.factors = TRUE)
           }
           out <- list(extras=prepped.dat$train$extra, train=train_dat, test=test_dat, 
                       ranger_mod=ranger_mod, class=class, id=id)
           out
         })
  })

```


#### `r colorize("4. Assess the models", "blue")`

**Predict the test data and merge with true class**

```{r}
list.of.forest_predictions <- map2(list.of.models, list.of.test, function(model, dat){  
  mod.list <- map(model, "ranger_mod")  
  prep.test.list <- map(model, "test")  
  class.list <- map(dat, function(x) x |> select("id", "census_region"))
  predictions.list <- pmap(list(mod.list, prep.test.list, class.list), 
                           function(mod, prep.test, class) {
                             predictions <- predict(mod, prep.test)$predictions  #note predict.all = FALSE 
                             bind_cols(class, prediction=predictions)}
  )}
)
  
```


**Pull out individual tree decisions for each observation, and identify observations with unique levels in the testing data.**

```{r, message=FALSE}
doParallel::registerDoParallel()

list.of.tree_predictions <- map2(list.of.models, list.of.test, function(model, dat){
  mod.list <- map(model, "ranger_mod")
  prep.test.list <- map(model, "test")
  extras.list <- map(model, "extras")
  class.list <- map(model, "class")
  id.list <- map(model, "id")
  test.list <- dat # original, untransformed data
  predictions.list <- pmap(list(mod.list, prep.test.list, extras.list, class.list, id.list, test.list),
    function(mod, prep.test, extras, class, id, test) {
      uniques <- is_unique(data=test, list_of_extras=extras)
      tree_preds <- predict_by_tree(mod=mod, new_data=prep.test, new_unique=uniques, id=id)
      tree_preds |> left_join(test |> select(id, any_of(class)), by="id")}
    )}
  )

```

**Pull out individual tree predictions from ranger to compare with ours**

```{r, eval=FALSE, include=FALSE}
list.of.tree_predictions_from_ranger <- map2(list.of.models, list.of.test, function(model, dat){  
  mod.list <- map(model, "ranger_mod")  
  prep.test.list <- map(model, "test")  
  class.list <- map(dat, function(x) x |> select("id", "census_region"))
  predictions.list <- pmap(list(mod.list, prep.test.list, class.list), 
                           function(mod, prep.test, class) {
                             predictions <- predict(mod, prep.test, predict.all = TRUE)$predictions |>
                               as.data.frame()
                             names(predictions) <- paste('tree_', 1:ncol(predictions), sep='')
                             bind_cols(class, prediction=predictions) |>
                               pivot_longer(starts_with('tree'), names_to='tree', values_to='prediction', names_prefix='tree_') |>
                               mutate(tree = as.numeric(tree)) |>
                               mutate(prediction = factor(mod$forest$levels[prediction], levels=mod$forest$levels))
                             }
  )}
)

# check if these are the same
map2(list.of.tree_predictions_from_ranger, list.of.tree_predictions,
     function(x, y) {
       left_join(bind_rows(x, .id='fold'),
                 bind_rows(y, .id='fold'),
                 by=c('fold', 'id', 'census_region', 'tree')) |>
         filter(prediction.x != prediction.y)
     })

# check if these give the same result as the forest prediction
map2(list.of.forest_predictions, list.of.tree_predictions,
     function(x, y) {
       y |> bind_rows(.id='fold') |>
         group_by(id, fold, census_region) |>
         count(prediction) |> mutate(biggest = prediction[which.max(n)]) |>
         left_join(bind_rows(x, .id='fold'),
                   by=c('fold', 'id', 'census_region')) |>
         filter(biggest != prediction.y)
     })

```



**Forest misclassification rates**

Calculate the proportion of correct forest classifications (ie misclassification rate)

```{r, message=FALSE, warning=FALSE}
list.of.forest_mc <- map(list.of.forest_predictions, function(x) {
    # merge the folds
    preds <- bind_rows(x, .id="fold") 
    # weights for each fold
    w <- preds |> group_by(fold) |> tally() |> pull(n)
    # misclassification rates of the folds
    lm <- preds |> mutate(wrong = census_region != prediction) |>
      group_by(fold) |> summarise(mc = sum(wrong)/n()) |> 
      lm(mc ~ 1, weights = w, data=_) |> summary()
    # weighted mean and standard error of the misclassification rates
    av <- coef(lm)[,"Estimate"]
    se <- coef(lm)[,"Std. Error"]
    # confusion matrix
    conf <- preds |> group_by(fold, census_region, prediction) |> 
      summarise(n=n()) |> mutate(N=sum(n), p=n/sum(n)) |> ungroup() |>
      mutate(w = as.numeric(paste(factor(fold, labels=w))), 
             t_p = paste(census_region, prediction, sep="_")) |> 
      split(~t_p)
    # weighted mean and standard error of the confusion matrices
    conf.lm <- map(conf, function(x) {lm(p~1, weights=w, data=x) |> summary()})
    conf.av <- map(conf.lm, function(x) coef(x)[,"Estimate"])
    conf.se <- map(conf.lm, function(x) coef(x)[,"Std. Error"])
    out <- list(av=av, se=se, conf=conf, conf.av=conf.av, conf.se=conf.se)
    out})

#list.of.forest_mc |> map(pluck("av"))
#list.of.forest_mc |> map(pluck("se"))
```


**Tree misclassification rates**

Calculate misclassification rates of the individual trees according to the use of absent levels 
```{r, message=FALSE, warning=FALSE}

list.of.tree_mc <- map(list.of.tree_predictions, function(x){
    # merge the folds
    preds <- bind_rows(x, .id="fold") 
    # misclassification rates of the folds
    preds |> mutate(uses_unique = if_else(uses_unique == 0, "No", "Yes")) |>
      group_by(fold, uses_unique, census_region, prediction) |>
      summarise(n=n()) |>
      group_by(fold, uses_unique, census_region) |>
      mutate(N = sum(n)) |>
      mutate(prop = n/N)
})

```



```{r, message=FALSE, echo=FALSE, warning=FALSE}

results <- map2(list.of.tree_predictions, list.of.forest_predictions, function(tree, forest){
  #tree: misclassification rate
  tree.mc <- tree |> bind_rows() |> mutate(uses_unique = if_else(uses_unique == 0, "No", "Yes")) |>
    group_by(uses_unique, census_region, prediction) |>
    summarise(n=n()) |>
    group_by(uses_unique, census_region) |>
    mutate(N = sum(n)) |>
    mutate(prop = n/N)
  tree.yes <- tree.mc |> ungroup() |> filter(uses_unique=="Yes") |> arrange(desc(prop)) |> 
    select(census_region, prediction, prop) |> 
    mutate(census_region=make.names(census_region), prediction=make.names(prediction))
  tree.no <- tree.mc |> ungroup() |> filter(uses_unique=="No") |> arrange(desc(prop)) |> 
    select(census_region, prediction, prop) |> 
    mutate(census_region=make.names(census_region), prediction=make.names(prediction))
  tree.mc <- right_join(tree.yes, tree.no, by=c("census_region", "prediction"), suffix=c(".yes",".no"))
  
  #forest: misclassification rate
  forest.mc <- forest |> bind_rows() |> group_by(census_region, prediction) |> 
    summarise(n=n()) |> mutate(N = sum(n)) |> mutate(prop = n/N) |> select(-n,-N) |> 
    mutate(census_region = make.names(census_region), prediction = make.names(prediction))
  
  #merge
  left_join(tree.mc, forest.mc, by=c("census_region", "prediction")) |> 
    rename(tree.absent=prop.yes,tree.no.absent=prop.no,forest=prop)
})


```

```{r, include=FALSE}
#save(results, file="Cerda_mc_results_500trees_36axes.R")
load(here("Cerda_midwest/midwest_data/Cerda_mc_results_500trees_36axes.R"))  #results
```

**Plot of forest misclassification rates**

```{r, out.width="100%", echo=FALSE, warning=FALSE}
p1 <- results |> bind_rows(.id="method") |> 
  pivot_longer(cols=c(tree.absent, tree.no.absent, forest), names_to = "result", values_to = "p") |> 
  filter(result == "forest") |> 
  filter(prediction == census_region) |> 
  mutate(method = factor(method, levels=names(list.of.data))) |> 
  mutate(across(where(is.character), factor)) |> 
  mutate(pch = ifelse(census_region==prediction, 21,1)) |> 
  ggplot(aes(x=prediction, y=p)) + 
  geom_point(aes(colour=census_region, shape=I(pch), bg=census_region), size=3) +
  theme_bw(base_size = 11) + 
  scale_y_continuous("Proportion of predictions\n",expand=c(0.03,0.03),limits=c(0,1)) +
  #theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(strip.text.y = element_text(size = 8)) +
  facet_wrap(~method, nrow=1) +
  labs(x="\nPredicted census region", colour="True census region", bg="True census region")

p1
```

**Plot of tree misclassification rates**

```{r, out.width="100%", fig.height=12, echo=FALSE, warning=FALSE}
p2 <- results |> bind_rows(.id="method") |> 
  pivot_longer(cols=c(tree.absent, tree.no.absent, forest), names_to = "result", values_to = "p") |> 
  filter(result != "forest") |> 
  mutate(method = factor(method, levels=names(list.of.data))) |> 
  mutate(result = factor(result, levels=c("tree.absent", "tree.no.absent"))) |> 
  mutate(across(where(is.character), factor)) |> 
  mutate(pch = ifelse(census_region==prediction, 21,1)) |> 
  ggplot(aes(x=prediction, y=p, group=result)) + 
  geom_point(aes(colour=result, shape=I(pch), bg=result), size=3) +
  theme_bw(base_size = 11) + 
  scale_y_continuous("Proportion of predictions\n",expand=c(0.03,0.03),limits=c(0,1)) +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        strip.text.y = element_text(size = 8)) +
  facet_grid(census_region~method) +
  scale_colour_manual(values=c("#9d1001","#019d10"), labels=c("Yes", "No")) + 
  scale_fill_manual(values=c("#9d1001","#019d10"), labels=c("Yes", "No")) + 
  labs(x="\nPredicted census region", colour="Absent levels used in prediction", bg="Absent levels used in prediction")

p2
```

```{r, eval=FALSE, include=FALSE}
png("p1.png", width=960, height = 1024)
p1
dev.off()

png("p2.png", width=960, height = 1024)
p2
dev.off()

```
























