---
title: "Midwest survey using One-hot, CA, CA0, PCO, and Cerda methods"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
library(tidyverse)
```

```{r, echo=FALSE}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```

### `r colorize("Midwest survey using One-hot, CA, CA0, PCO, and Cerda methods", "blue")`

### 1. Load data

Midwest survey data from Cerda et al 2018.  
Survey to know if people self-identify as Midwesterners.  
Sample size:  2,778.   
Target variable (multiclass-clf): ‘Location (Census Region)’ (9 classes) - Cerda says 10 so perhaps includes missing, although they remove these rows anyway.
Cerda selected categorical variable: ‘In your own words, what would you call the part of the country you live in now?’ (cardinality: 1,008) - again Cerda had extra one perhaps for missing.  
Other explanatory variables: ‘Personally identification as a Midwesterner?’ (4 levels, ordinal), ‘Gender’ (2 levels), ‘Age’ (4 levels, ordinal), ‘Household Income’ (5 levels, ordinal), ‘Education’ (5 levels, ordinal), ‘Illinois (IL) in the Midwest?’, ‘IN?’, ‘IA?’, ‘KS?’, ‘MI?’, ‘MN?’, ‘MO?’, ‘NE?’, ‘ND?’, ‘OH?’, ‘SD?’, ‘WI?’, ‘AR?’, ‘CO?’, ‘KY?’, ‘OK?’, ‘PA?’, ’WV?’, ’MT?’, ‘WY?’ (each of these last variables are indicator variables, although an individual can belong to more than one).

```{r}
#midwest_raw <- read.csv("midwest/midwest_survey.csv", header=T, na.strings=c(""," ","NA"))
midwest_raw <- read.csv("midwest_survey.csv", header=T, na.strings=c(""," ","NA"))
str(midwest_raw)
midwest_raw |> map_df(function(x){x |> as.factor() |> nlevels()}) |> t()
```

**Data preprocessing:**

-- remove rows with missing values for the target variable or in any explanatory variable other than the selected categorical variable (reduces to 2421 observations);  
-- for the selected categorical variable replace missing entries by the string ‘nan’;  
-- transform all entries for the categorical variable to lower case;  
-- convert all variables to ordinal, binary, or nominal factors.

Note that Cerda 2018 standardized every column of the feature matrix to a unit variance


```{r}
midwest_tidy <- midwest_raw |> 
  # remove id because it contains rows that will be removed
  select(-id) |> 
  # fill in binary zeros
  mutate(across(IL:WY, \(.) {replace(.,is.na(.),0)})) |> 
  # remove rows with missing values for the target variable census_region
  filter(!is.na(census_region)) |> 
  # remove na from categorical_variable to avoid na in distance matrix
  # need to change to string (rather than "") so can use tidymodels with probability forests
  mutate(across(categorical_variable, \(.) {replace(.,is.na(.),"nan")})) |> 
  # remove rows with missing values for explanatory variables other than the selected categorical variable
  drop_na(where(is.character)) |> 
  # transform all entries for the categorical variable to lower case
  mutate(categorical_variable = tolower(categorical_variable)) |> 
  # re-add id
  rownames_to_column("id") |> 
  # convert ordinal variables to ordered factors
  mutate(education = factor(education, levels=c("Some college", "Less than high school degree", "High school degree", "Associate or bachelor degree", "Graduate degree"), ordered=TRUE, exclude = NULL), 
         age = factor(age, levels=c("18-29", "30-44", "45-60", "> 60"), ordered=TRUE, exclude = NULL), 
         household_income = factor(household_income, levels=c("$0 - $24,999", "$25,000 - $49,999", "$50,000 - $99,999", "$100,000 - $149,999", "$150,000+"), ordered=TRUE, exclude = NULL),
         personal_id = factor(personal_id, levels=c("Not at all","Not much","Some","A lot"), ordered=TRUE, exclude = NULL)) |> 
  # convert other variables to factors
  mutate(across(!where(is.factor), factor))
  
str(midwest_tidy)

```

**Calculate distance matrix** - Levenshtein distance "lv" ("hamming" only works when strings are the same length)

The categorical variables are either binary or ordinal apart from 'categorical_variable'.
Calculate a distance matrix for this variable only.

```{r}
d <- stringdist::stringdistmatrix(midwest_tidy$categorical_variable, midwest_tidy$categorical_variable, method = "lv", useNames = "names") 

d.pco <- stringdist::stringdistmatrix(midwest_tidy$categorical_variable |> unique(), midwest_tidy$categorical_variable |> unique(), method = "lv", useNames = "strings") 

```

**Calculate PCO scores**

Only required for 'categorical_variable'

```{r, message=FALSE}
#source("methods/helpers.R")       # Functions used internally in the methods
source("../methods/helpers.R")       # Functions used internally in the methods
epsilon <- sqrt(.Machine$double.eps)
mp <- 95
A <- -0.5 * d.pco^2
B <- dbl_center(A)
eigen_B <- eigen_decomp(B, symmetric=TRUE)
lambdas_B <- filter_eigenvalues(eigen_B$values, mp=mp) 
Qo <- eigen_B$vectors
Q <- sweep(Qo[, seq_len(length(lambdas_B)), drop=FALSE], 2, sqrt(abs(lambdas_B)), "*") # Scale eigenvectors
colnames(Q) <- paste0("PCO.",1:ncol(Q))
PCO <- data.frame(Q) |> rownames_to_column("categorical_variable")

```

Merge the data with the encoded categorical variable into a giant dataset (2421 x 2482)!
The different methods will use different encodings of the categorical_variable column :
Cerda method will use the `r {midwest_tidy |> select(starts_with("V")) |> ncol()}` columns starting with "V", 
PCO method will use the `r {midwest_tidy |> select(starts_with("PCO")) |> ncol()}` columns starting with "PCO" (which captures `r {mp}`% of the variation),
CA and CA0 methods will use the uncoded categorical_variable column.

```{r, message=FALSE}
midwest <- midwest_tidy |> 
  left_join(d |> as.data.frame() |> rownames_to_column("id") |> mutate(id=factor(id)), by="id") |> 
  left_join(PCO |> mutate(categorical_variable=factor(categorical_variable)), by="categorical_variable") 

midwest |> as_tibble()

```

Because ranger will re-order the training and testing data independently, there is the chance of a certain level being converted to a different integer in each set. For unordered factors this happens when the order of first occurrence differs between the two data sets. It doesn't seem to be a problem for ordered factors (the absent level will go right no matter where it is ordered). For PCO method can convert ordinal factors to numeric.

```{r}
midwest |> select(where(is.ordered)) |> map(levels)
midwest <- midwest |> bind_cols(midwest |> select(where(is.ordered)) |> mutate(across(everything(), as.numeric)) |> 
                       set_names(paste(colnames(midwest |> select(where(is.ordered))), "numeric", sep="_")))
```

### 2. Load methods

**Load libraries and functions**

```{r}
# Load libraries
library(ranger)
library(caret)   # for createFolds

# Load in our functions (PCO not required as pre-transforming data)
source("../methods/tree_predictions.R") # to pull out individual tree predictions
source("../methods/ranger_mods.R")
source("../methods/ca.R") # CA method
source("../methods/ca_binary.R") # Binary method
source("../methods/ca_unbiased.R")   # CA method with new levels scored as zero
source("../methods/do_nothing.R")

```

**Split data into training and test sets using folds**

```{r}
set.seed(3)
flds <- createFolds(y=midwest$census_region, k=10) 

```

**Define the data**

The different encoding methods  will use different columns of data. 
The core variables will be used by all the methods, but the PCO method will use the numeric columns for the ordinal factors.
CA, Binary, and CA_unbiased all use the same columns.

```{r}
core_vars <- midwest |> select(!where(is.numeric) & -categorical_variable & -respondent) |> colnames()
core_vars_numeric <- midwest |> select(!where(is.ordered) & !starts_with("V") & !starts_with("PCO") & -categorical_variable & -respondent) |> colnames()
```

Add a prefix to all the predictor variables names (function requirement!).

```{r}
ca.dat <- midwest |> select(all_of(core_vars), categorical_variable) |> rename_with(.fn = function(.x){paste0("Var_", .x)}, .cols=-c(id, census_region))
pco.dat <- midwest |> select(all_of(core_vars_numeric), starts_with("PCO")) |> rename_with(.fn = function(.x){paste0("Var_", .x)}, .cols=-c(id, census_region))
cerda.dat <- midwest |> select(all_of(core_vars), starts_with("V")) |> rename_with(.fn = function(.x){paste0("Var_", .x)}, .cols=-c(id, census_region))

```

Merge into a single list of datasets and split into training and test sets
```{r}
list.of.data <- list(ca=ca.dat, binary=ca.dat, ca0=ca.dat, pco=pco.dat, cerda=cerda.dat)

list.of.train <- map(list.of.data,
                     function(x) {map(flds, ~slice(x, {-.}))})

list.of.test <- map(list.of.data,
                    function(x) {map(flds, ~slice(x, .))})
```

The CA_unbiased and binary methods will require the prepare_training step.  
The CA, PCO, and Cerda methods will use the transformed data straight into `ranger()`. 
Note that the ca method doesn't allow for numeric columns or else we could just use the ca method on the transformed data.

Train the random forest models

```{r}
list.of.methods <- list(ca="raw", binary="binary",ca0="ca0", pco="raw",cerda="raw")

list.of.models <- pmap(list(list.of.train, list.of.test, list.of.methods),
     function(x, y, z) {
       map2(x, y, ~rf_model(.x, .y, method=z, class = "census_region", id="id", var_id="Var_", ntrees=5))
     })
```

Predict the test data and merge with true class

```{r}
list.of.forest_predictions <- map2(list.of.models, list.of.test, function(model, dat){  # list of 5 methods
  mod.list <- map(model, "ranger_mod")  # list of 10 ranger models
  test.list <- map(model, "test")       # list of 10 test sets
  class.list <- map(dat, function(x) x |> select("id", "census_region"))  # list of 10 data frames with id and class
  predictions.list <- pmap(list(mod.list, test.list, class.list), 
                           function(mod, test, class) {
                             predictions <- predict(mod, test)$predictions  #note predict.all = FALSE 
                             bind_cols(class, prediction=predictions)}
                           )}
  )
  
```

Calculate the proportion of correct forest classifications (ie misclassification rate)

```{r}
list.of.forest_mc <- map(list.of.forest_predictions, function(x) {
    # merge the folds
    preds <- bind_rows(x, .id="fold") 
    # weights for each fold
    w <- preds |> group_by(fold) |> tally() |> pull(n)
    # misclassification rates of the folds
    lm <- preds |> mutate(wrong = census_region != prediction) |>
      group_by(fold) |> summarise(mc = sum(wrong)/n()) |> 
      lm(mc ~ 1, weights = w, data=_) |> summary()
    # weighted mean and standard error of the misclassification rates
    av <- coef(lm)[,"Estimate"]
    se <- coef(lm)[,"Std. Error"]
    # confusion matrix
    conf <- preds |> group_by(fold, census_region, prediction) |> 
      summarise(n=n()) |> mutate(N=sum(n), p=n/sum(n)) |> ungroup() |>
      mutate(w = as.numeric(paste(factor(fold, labels=w))), 
             t_p = paste(census_region, prediction, sep="_")) |> 
      split(~t_p)
    # weighted mean and standard error of the confusion matrices
    conf.lm <- map(conf, function(x) {lm(p~1, weights=w, data=x) |> summary()})
    conf.av <- map(conf.lm, function(x) coef(x)[,"Estimate"])
    conf.se <- map(conf.lm, function(x) coef(x)[,"Std. Error"])
    out <- list(av=av, se=se, conf.av=conf.av, conf.se=conf.se)
    out})

list.of.forest_mc |> map(pluck("av"))
list.of.forest_mc |> map(pluck("se"))
```

```{r}
library(yardstick)
library(gridExtra)

list.of.heatmaps <- pmap(
  list(
    list.of.forest_predictions, 
    names(list.of.forest_predictions), 
    list("darkred", "orange", "chartreuse4", "dodgerblue4", "violet")
    ), 
  function(preds, name, col) {
    (bind_rows(preds, .id="fold") |> conf_mat(census_region, prediction))[[1]] |> as.data.frame() |> 
    mutate(Truth = factor(Truth, levels=rev(levels(Truth)))) |> 
    ggplot(aes(x=Prediction, y=Truth)) + 
    geom_tile(aes(fill= Freq)) +
    geom_text(aes(label = Freq)) +
    scale_fill_gradient(low="#eeeeee", high=col) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90), legend.position = "bottom") +
    labs(title=name)
    })
    
do.call("grid.arrange", c(list.of.heatmaps, ncol=5))
```

Pull out individual tree decisions for each observation,  
identify observations with unique levels in the testing data,  
and calculate misclassification rates of the individual trees according to the use of absent levels 



```{r}
list.of.tree_predictions <- map2(list.of.models, list.of.test, function(model, dat){
  mod.list <- map(model, "ranger_mod")
  train.list <- map(model, "train")
  prep.test.list <- map(model, "test")
  test.list <- dat
  class.list <- map(model, "class")
  id.list <- map(model, "id")
  predictions.list <- pmap(list(mod.list, train.list, prep.test.list, class.list, id.list, test.list),
    function(mod, train, prep.test, class, id, test) {
      uniques <- is_unique(data=test, list_of_extras=train$extra)
      tree_preds <- predict_by_tree(mod=mod, new_data=prep.test, new_unique=uniques, id=id)
      tree_preds |> left_join(test |> select(id, any_of(class)), by="id")}
    )}
  )

list.of.tree_mc <- map(list.of.tree_predictions, function(x){
  x |> bind_rows() |> 
    mutate(uses_unique = if_else(uses_unique == 0, "No", "Yes")) |>
    group_by(uses_unique, census_region, prediction) |>
    summarise(n=n()) |>
    group_by(uses_unique, census_region) |>
    mutate(N = sum(n)) |>
    mutate(prop = n/N)
})

```

### `r colorize("Something isn't right", "red")`
 ... look at census_region East North Central which was incorrectly predicted as West North Central. 
The forest misclassification rates for this combination were low (less than 0.1) but the tree misclassification rates were extremely high (greater than 65%).
What is going on?????????????????

```{r}
list.of.tree_mc |> map(function(x){x |> filter(census_region == "East North Central", prediction == "West South Central")})
list.of.forest_mc |> map(function(x){x |> pluck("conf.av","East North Central_West South Central")})
```


